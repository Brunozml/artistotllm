{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121c5c9b-4f63-44ab-a8a4-00010ab94eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"ngrams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542625ab-3957-497f-a43c-b3e9d9f07bcf",
   "metadata": {},
   "source": [
    "### Punctuation and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eede3ccd-ff30-486a-bc79-96d7104e2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "EN_STOP = set(stopwords.words(\"english\"))\n",
    "\n",
    "def extract_stopwords(df: pd.DataFrame,\n",
    "                      text_cols=(\"y_train\", \"y_pred\", \"y_test\"),\n",
    "                      stopword_set=EN_STOP,\n",
    "                      regex=r\"\\b\\w+\\b\"):\n",
    "    \"\"\"\n",
    "    Add new *_stopwords columns that contain the stop-words found\n",
    "    in each corresponding text column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The frame that already contains the text columns.\n",
    "    text_cols : tuple[str]\n",
    "        Column names you want processed.\n",
    "    stopword_set : set[str]\n",
    "        The words to treat as stop-words (default = English NLTK list).\n",
    "    regex : str\n",
    "        Tokenisation pattern (default = words made of letters/digits).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The same frame, with extra columns like 'y_train_stopwords'.\n",
    "    \"\"\"\n",
    "    tokeniser = re.compile(regex).findall\n",
    "\n",
    "    def row_stops(txt):\n",
    "        return [t for t in tokeniser(str(txt).lower()) if t in stopword_set]\n",
    "\n",
    "    for col in text_cols:\n",
    "        df[f\"{col}_stopwords\"] = df[col].apply(row_stops)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ec7757-b04a-44d9-b73b-7355006f5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_stopwords(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60056e3-0d4a-45fa-8bc0-6aacd7802a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from typing import Dict, Tuple, Iterable, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  shared resources\n",
    "# ----------------------------------------------------------------------\n",
    "ENGLISH_STOPWORDS: List[str] = stopwords.words(\"english\")\n",
    "EN_STOP = set(ENGLISH_STOPWORDS)          # fast membership test\n",
    "TOKEN_PATTERN = re.compile(r\"\\b\\w+\\b\").findall\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  low-level helpers  (almost exactly your original code)\n",
    "# ----------------------------------------------------------------------\n",
    "def extract_stopwords(text: str | None) -> List[str]:\n",
    "    \"\"\"Return the stop-words that actually appear in *text* (lower-cased).\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = TOKEN_PATTERN(str(text).lower())\n",
    "    return [tok for tok in tokens if tok in EN_STOP]\n",
    "\n",
    "\n",
    "def get_stopword_distribution(text: str | None) -> Dict[str, float]:\n",
    "    \"\"\"Normalized frequency of each stop-word + a 'density' feature.\"\"\"\n",
    "    stopword_tokens = extract_stopwords(text)\n",
    "    counts = Counter(stopword_tokens)\n",
    "    total = sum(counts.values()) or 1                         # avoid /0\n",
    "    # vector with *all* standard stop-words (missing ones → 0)\n",
    "    dist = {w: counts.get(w, 0) / total for w in ENGLISH_STOPWORDS}\n",
    "\n",
    "    # density = stop-words per word\n",
    "    word_cnt = len(word_tokenize(str(text or \"\").lower()))\n",
    "    dist[\"density\"] = len(stopword_tokens) / word_cnt if word_cnt else 0\n",
    "    return dist\n",
    "\n",
    "\n",
    "def stopwords_similarity(text1: str | None,\n",
    "                         text2: str | None) -> Tuple[float, Dict]:\n",
    "    \"\"\"Cosine similarity between the two distributions + rich diagnostics.\"\"\"\n",
    "    d1, d2 = get_stopword_distribution(text1), get_stopword_distribution(text2)\n",
    "\n",
    "    features = ENGLISH_STOPWORDS + [\"density\"]\n",
    "    v1 = np.array([d1[f] for f in features])\n",
    "    v2 = np.array([d2[f] for f in features])\n",
    "\n",
    "    sim = (np.dot(v1, v2) /\n",
    "           (np.linalg.norm(v1) * np.linalg.norm(v2))) if v1.any() and v2.any() else 0.0\n",
    "\n",
    "    # optional detail payload (trim to first 20 stop-words for readability)\n",
    "    most1, most2 = Counter(extract_stopwords(text1)).most_common(10), \\\n",
    "                   Counter(extract_stopwords(text2)).most_common(10)\n",
    "    top_overlap = len({w for w, _ in most1}.intersection({w for w, _ in most2}))\n",
    "\n",
    "    details = {\n",
    "        \"text1_stats\": {\"most_common\": most1, \"density\": d1[\"density\"]},\n",
    "        \"text2_stats\": {\"most_common\": most2, \"density\": d2[\"density\"]},\n",
    "        \"top10_overlap\": top_overlap,\n",
    "        \"similarity\": sim\n",
    "    }\n",
    "    return sim, details\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3.  DataFrame-level helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def add_stopword_columns(df: pd.DataFrame,\n",
    "                         text_cols: Iterable[str] = (\"y_train\", \"y_pred\", \"y_test\")\n",
    "                         ) -> pd.DataFrame:\n",
    "    \"\"\"Add a <col>_stopwords list column for every *text_cols* entry.\"\"\"\n",
    "    for col in text_cols:\n",
    "        df[f\"{col}_stopwords\"] = df[col].apply(extract_stopwords)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_stopword_similarity(df: pd.DataFrame,\n",
    "                            pairs: Iterable[Tuple[str, str]] = (\n",
    "                                (\"y_train\", \"y_pred\"),\n",
    "                                (\"y_pred\", \"y_test\"),\n",
    "                                (\"y_train\", \"y_test\")\n",
    "                            ),\n",
    "                            keep_details: bool = False\n",
    "                            ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each (colA, colB) pair, append a cosine-similarity score column.\n",
    "\n",
    "    • Column is named  '<colA>_vs_<colB>_stop_sim'.  \n",
    "    • If *keep_details* is True, a second column with the same stem\n",
    "      plus '_details' is added containing the verbose diagnostics dict.\n",
    "    \"\"\"\n",
    "    for a, b in pairs:\n",
    "        sim_col = f\"{a}_vs_{b}_stop_sim\"\n",
    "        if keep_details:\n",
    "            det_col = f\"{a}_vs_{b}_stop_sim_details\"\n",
    "\n",
    "            def _pair(row):\n",
    "                sim, det = stopwords_similarity(row[a], row[b])\n",
    "                return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "            df[[sim_col, det_col]] = df.apply(_pair, axis=1)\n",
    "        else:\n",
    "            df[sim_col] = df.apply(lambda r: stopwords_similarity(r[a], r[b])[0],\n",
    "                                   axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4.  Example usage\n",
    "\n",
    "df = add_stopword_columns(df)\n",
    "df = add_stopword_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04db66a9-cde0-46b8-9568-a94d94d6450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from typing import Dict, Tuple, Iterable, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  shared resources\n",
    "# ----------------------------------------------------------------------\n",
    "PUNCTUATION_CHARS: List[str] = list(string.punctuation)        # 32 ASCII marks\n",
    "PUNCT_SET = set(PUNCTUATION_CHARS)\n",
    "PUNCT_PATTERN = re.compile(f\"[{re.escape(string.punctuation)}]\")  # matches ONE mark\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  low-level helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def extract_punctuation(text: str | None) -> List[str]:\n",
    "    \"\"\"Return *every* punctuation mark that appears in *text* (one per hit).\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    return PUNCT_PATTERN.findall(str(text))\n",
    "\n",
    "\n",
    "def get_punctuation_distribution(text: str | None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Normalised frequency of each ASCII punctuation mark (+ 'density').\n",
    "\n",
    "    • Density = punctuation marks per *character* (not word) so it stays\n",
    "      meaningful even for very short snippets such as “Hi!”.\n",
    "    \"\"\"\n",
    "    tokens = extract_punctuation(text)\n",
    "    counts = Counter(tokens)\n",
    "    total = sum(counts.values()) or 1\n",
    "\n",
    "    dist = {ch: counts.get(ch, 0) / total for ch in PUNCTUATION_CHARS}\n",
    "\n",
    "    char_count = len(str(text or \"\"))\n",
    "    dist[\"density\"] = len(tokens) / char_count if char_count else 0\n",
    "    return dist\n",
    "\n",
    "\n",
    "def punctuation_similarity(text1: str | None,\n",
    "                           text2: str | None) -> Tuple[float, Dict]:\n",
    "    \"\"\"Cosine-similarity of punctuation distributions + handy diagnostics.\"\"\"\n",
    "    d1, d2 = (get_punctuation_distribution(text1),\n",
    "              get_punctuation_distribution(text2))\n",
    "\n",
    "    feats = PUNCTUATION_CHARS + [\"density\"]\n",
    "    v1 = np.array([d1[f] for f in feats])\n",
    "    v2 = np.array([d2[f] for f in feats])\n",
    "\n",
    "    sim = (np.dot(v1, v2) /\n",
    "           (np.linalg.norm(v1) * np.linalg.norm(v2))) if v1.any() and v2.any() else 0.0\n",
    "\n",
    "    most1, most2 = Counter(extract_punctuation(text1)).most_common(5), \\\n",
    "                   Counter(extract_punctuation(text2)).most_common(5)\n",
    "    overlap = len({ch for ch, _ in most1}.intersection({ch for ch, _ in most2}))\n",
    "\n",
    "    details = {\n",
    "        \"text1_stats\": {\"most_common\": most1, \"density\": d1[\"density\"]},\n",
    "        \"text2_stats\": {\"most_common\": most2, \"density\": d2[\"density\"]},\n",
    "        \"top5_overlap\": overlap,\n",
    "        \"similarity\": sim\n",
    "    }\n",
    "    return sim, details\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3.  DataFrame-level helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def add_punctuation_columns(df: pd.DataFrame,\n",
    "                            text_cols: Iterable[str] = (\"y_train\",\n",
    "                                                        \"y_pred\",\n",
    "                                                        \"y_test\")\n",
    "                            ) -> pd.DataFrame:\n",
    "    \"\"\"Add a <col>_punct list column for every *text_cols* entry.\"\"\"\n",
    "    for col in text_cols:\n",
    "        df[f\"{col}_punct\"] = df[col].apply(extract_punctuation)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_punctuation_similarity(df: pd.DataFrame,\n",
    "                               pairs: Iterable[Tuple[str, str]] = (\n",
    "                                   (\"y_train\", \"y_pred\"),\n",
    "                                   (\"y_pred\", \"y_test\"),\n",
    "                                   (\"y_train\", \"y_test\")\n",
    "                               ),\n",
    "                               keep_details: bool = False\n",
    "                               ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append cosine-similarity columns for each (colA, colB) pair based on punctuation.\n",
    "\n",
    "    • Column:  '<colA>_vs_<colB>_punct_sim'  \n",
    "    • If *keep_details* is True, also add '<pair>_punct_sim_details' with diagnostics.\n",
    "    \"\"\"\n",
    "    for a, b in pairs:\n",
    "        sim_col = f\"{a}_vs_{b}_punct_sim\"\n",
    "\n",
    "        if keep_details:\n",
    "            det_col = f\"{a}_vs_{b}_punct_sim_details\"\n",
    "\n",
    "            def _pair(row):\n",
    "                sim, det = punctuation_similarity(row[a], row[b])\n",
    "                return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "            df[[sim_col, det_col]] = df.apply(_pair, axis=1)\n",
    "        else:\n",
    "            df[sim_col] = df.apply(lambda r: punctuation_similarity(r[a], r[b])[0],\n",
    "                                   axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4.  Example quick-test\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "df = add_punctuation_columns(df)\n",
    "df = add_punctuation_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c01c4f-4e63-4d3e-b850-c1b17781b9c5",
   "metadata": {},
   "source": [
    "### TTR Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea9baf50-e2d2-44f3-9d00-48a956ce3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, remove_stopwords: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocess text by tokenizing, lowercasing, and optionally removing stopwords.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to preprocess\n",
    "        remove_stopwords (bool): Whether to remove stopwords\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Preprocessed tokens\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove non-alphabetic tokens\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    \n",
    "    # Optionally remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def calculate_ttr(tokens: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Type-Token Ratio (TTR).\n",
    "    \n",
    "    Args:\n",
    "        tokens (List[str]): List of tokens from the text\n",
    "        \n",
    "    Returns:\n",
    "        float: The Type-Token Ratio value\n",
    "    \"\"\"\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    \n",
    "    n_types = len(set(tokens))  # Number of unique words\n",
    "    n_tokens = len(tokens)      # Total number of words\n",
    "    \n",
    "    return n_types / n_tokens\n",
    "\n",
    "def moving_average_ttr(tokens: List[str], window_size: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Moving-Average Type-Token Ratio (MATTR).\n",
    "    \n",
    "    Args:\n",
    "        tokens (List[str]): List of tokens from the text\n",
    "        window_size (int): Size of the sliding window\n",
    "        \n",
    "    Returns:\n",
    "        float: The MATTR value\n",
    "    \"\"\"\n",
    "    if len(tokens) < window_size:\n",
    "        return calculate_ttr(tokens)\n",
    "    \n",
    "    # Calculate TTR for each window and take the average\n",
    "    ttrs = []\n",
    "    for i in range(len(tokens) - window_size + 1):\n",
    "        window = tokens[i:i+window_size]\n",
    "        ttrs.append(calculate_ttr(window))\n",
    "    \n",
    "    return sum(ttrs) / len(ttrs)\n",
    "\n",
    "def mtld(tokens: List[str], threshold: float = 0.72) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Measure of Textual Lexical Diversity (MTLD).\n",
    "    \n",
    "    Args:\n",
    "        tokens (List[str]): List of tokens from the text\n",
    "        threshold (float): The TTR threshold for factor count\n",
    "        \n",
    "    Returns:\n",
    "        float: The MTLD value\n",
    "    \"\"\"\n",
    "    if len(tokens) < 50:  # Too short for reliable MTLD\n",
    "        return 0\n",
    "    \n",
    "    def mtld_pass(tokens, threshold):\n",
    "        # Forward pass\n",
    "        factors = 0\n",
    "        types_so_far = set()\n",
    "        token_count = 0\n",
    "        \n",
    "        for token in tokens:\n",
    "            token_count += 1\n",
    "            types_so_far.add(token)\n",
    "            ttr = len(types_so_far) / token_count\n",
    "            \n",
    "            if ttr <= threshold:\n",
    "                factors += 1\n",
    "                types_so_far = set()\n",
    "                token_count = 0\n",
    "        \n",
    "        if token_count > 0:\n",
    "            ttr = len(types_so_far) / token_count\n",
    "            partial_factor = (1 - ttr) / (1 - threshold)\n",
    "            factors += partial_factor\n",
    "        \n",
    "        return len(tokens) / factors if factors > 0 else 0\n",
    "    \n",
    "    # Calculate MTLD as the average of forward and backward passes\n",
    "    forward = mtld_pass(tokens, threshold)\n",
    "    backward = mtld_pass(tokens[::-1], threshold)\n",
    "    \n",
    "    return (forward + backward) / 2\n",
    "\n",
    "def ttr_similarity(text1: str, text2: str, include_stopwords: bool = True) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Compare two texts based on their lexical diversity (TTR) metrics.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): First text to compare\n",
    "        text2 (str): Second text to compare\n",
    "        include_stopwords (bool): Whether to include stopwords in the analysis\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[float, Dict]: A tuple containing:\n",
    "            - A similarity score between 0-1\n",
    "            - A dictionary with detailed metrics\n",
    "    \"\"\"\n",
    "    # Preprocess texts\n",
    "    tokens1 = preprocess_text(text1, remove_stopwords=not include_stopwords)\n",
    "    tokens2 = preprocess_text(text2, remove_stopwords=not include_stopwords)\n",
    "    \n",
    "    # Calculate basic TTR for both texts\n",
    "    ttr1 = calculate_ttr(tokens1)\n",
    "    ttr2 = calculate_ttr(tokens2)\n",
    "    \n",
    "    # Calculate MATTR for both texts\n",
    "    mattr1 = moving_average_ttr(tokens1)\n",
    "    mattr2 = moving_average_ttr(tokens2)\n",
    "    \n",
    "    # Calculate MTLD for both texts\n",
    "    mtld1 = mtld(tokens1)\n",
    "    mtld2 = mtld(tokens2)\n",
    "    \n",
    "    # Calculate similarity scores (1 - normalized absolute difference)\n",
    "    ttr_sim = 1 - abs(ttr1 - ttr2) / max(ttr1, ttr2) if max(ttr1, ttr2) > 0 else 1\n",
    "    mattr_sim = 1 - abs(mattr1 - mattr2) / max(mattr1, mattr2) if max(mattr1, mattr2) > 0 else 1\n",
    "    mtld_sim = 1 - abs(mtld1 - mtld2) / max(mtld1, mtld2) if max(mtld1, mtld2) > 0 else 1\n",
    "    \n",
    "    # Calculate overall similarity (weighted average)\n",
    "    overall_sim = (ttr_sim * 0.3) + (mattr_sim * 0.4) + (mtld_sim * 0.3)\n",
    "    \n",
    "    # Prepare detailed output\n",
    "    details = {\n",
    "        \"ttr\": {\n",
    "            \"text1\": ttr1, \n",
    "            \"text2\": ttr2, \n",
    "            \"similarity\": ttr_sim\n",
    "        },\n",
    "        \"mattr\": {\n",
    "            \"text1\": mattr1, \n",
    "            \"text2\": mattr2, \n",
    "            \"similarity\": mattr_sim\n",
    "        },\n",
    "        \"mtld\": {\n",
    "            \"text1\": mtld1, \n",
    "            \"text2\": mtld2, \n",
    "            \"similarity\": mtld_sim\n",
    "        },\n",
    "        \"text1_stats\": {\n",
    "            \"tokens\": len(tokens1), \n",
    "            \"unique_tokens\": len(set(tokens1)),\n",
    "            \"lexical_density\": len(set(tokens1)) / len(tokens1) if tokens1 else 0\n",
    "        },\n",
    "        \"text2_stats\": {\n",
    "            \"tokens\": len(tokens2), \n",
    "            \"unique_tokens\": len(set(tokens2)),\n",
    "            \"lexical_density\": len(set(tokens2)) / len(tokens2) if tokens2 else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return overall_sim, details\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  once-per-session NLTK housekeeping\n",
    "# ----------------------------------------------------------------------\n",
    "import nltk\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "from nltk.tokenize import word_tokenize           # used inside preprocess_text\n",
    "from nltk.corpus import stopwords                 #    \"      \"      \"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  DataFrame-level helper\n",
    "# ----------------------------------------------------------------------\n",
    "from typing import Iterable, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def add_ttr_similarity(df: pd.DataFrame,\n",
    "                       pairs: Iterable[Tuple[str, str]] = (\n",
    "                           (\"y_train\", \"y_pred\"),\n",
    "                           (\"y_pred\",  \"y_test\"),\n",
    "                           (\"y_train\", \"y_test\")\n",
    "                       ),\n",
    "                       include_stopwords: bool = True,\n",
    "                       keep_details: bool = False\n",
    "                       ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append a lexical-diversity similarity column for each (colA, colB) pair.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Your frame containing the text columns.\n",
    "    pairs : iterable[tuple[str, str]]\n",
    "        Column name pairs to compare (default = the three pair-wise combos\n",
    "        of 'y_train', 'y_pred', 'y_test').\n",
    "    include_stopwords : bool\n",
    "        Passed straight through to `ttr_similarity()`.\n",
    "    keep_details : bool\n",
    "        • False  → add only '<colA>_vs_<colB>_ttr_sim' (float 0–1).  \n",
    "        • True   → also add '<pair>_ttr_sim_details' with the full metrics dict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The same frame, with the new similarity (and optional details) columns.\n",
    "    \"\"\"\n",
    "    for a, b in pairs:\n",
    "        sim_col = f\"{a}_vs_{b}_ttr_sim\"\n",
    "\n",
    "        if keep_details:\n",
    "            det_col = f\"{a}_vs_{b}_ttr_sim_details\"\n",
    "\n",
    "            def _compare(row):\n",
    "                sim, det = ttr_similarity(row[a],\n",
    "                                          row[b],\n",
    "                                          include_stopwords=include_stopwords)\n",
    "                return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "            df[[sim_col, det_col]] = df.apply(_compare, axis=1)\n",
    "\n",
    "        else:\n",
    "            df[sim_col] = df.apply(\n",
    "                lambda r: ttr_similarity(r[a],\n",
    "                                         r[b],\n",
    "                                         include_stopwords=include_stopwords)[0],\n",
    "                axis=1\n",
    "            )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b9dc589-f929-4985-b94f-c94f941ef601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_ttr_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ee5b9-0a1a-4082-8bc2-de5e09e59092",
   "metadata": {},
   "source": [
    "### Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d887e8d-ac02-40ea-8e4e-10921f2a4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# import numpy as np\n",
    "# from typing import Tuple\n",
    "\n",
    "# def load_model():\n",
    "#     \"\"\"Load the Sentence-BERT model\"\"\"\n",
    "#     return SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# def transformer_similarity(text1: str, text2: str, model=None) -> Tuple[float, dict]:\n",
    "#     \"\"\"\n",
    "#     Compare two texts using Sentence Transformers.\n",
    "#     Returns a similarity score and the sentence embeddings.\n",
    "#     \"\"\"\n",
    "#     if model is None:\n",
    "#         model = load_model()\n",
    "    \n",
    "#     # Get embeddings\n",
    "#     embedding1 = model.encode([text1])[0]\n",
    "#     embedding2 = model.encode([text2])[0]\n",
    "    \n",
    "#     # Calculate cosine similarity\n",
    "#     similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "    \n",
    "#     return similarity, {\n",
    "#         \"embedding1_sample\": embedding1[:5].tolist(),  # Show first 5 dimensions\n",
    "#         \"embedding2_sample\": embedding2[:5].tolist()\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 0.  one-time model load  (do this once per Python session)\n",
    "# # ------------------------------------------------------------------\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from typing import Iterable, Tuple\n",
    "\n",
    "# _SBERT_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")   # ~80 MB, tiny + fast\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 1.  low-level single-pair similarity function\n",
    "# # ------------------------------------------------------------------\n",
    "# def transformer_similarity(text1: str | None,\n",
    "#                            text2: str | None,\n",
    "#                            model: SentenceTransformer = _SBERT_MODEL\n",
    "#                            ) -> Tuple[float, dict]:\n",
    "#     \"\"\"\n",
    "#     Cosine similarity between the two sentence-level embeddings.\n",
    "#     Returns (similarity, small-diagnostics-dict).\n",
    "#     \"\"\"\n",
    "#     text1 = text1 or \"\"\n",
    "#     text2 = text2 or \"\"\n",
    "#     emb1, emb2 = model.encode([text1, text2], normalize_embeddings=True)\n",
    "\n",
    "#     # cosine on **already L2-normalised** vectors = simple dot product\n",
    "#     similarity = float(np.dot(emb1, emb2))\n",
    "\n",
    "#     details = {\n",
    "#         \"embedding1_sample\": emb1[:5].tolist(),   # first 5 dims for sanity-check\n",
    "#         \"embedding2_sample\": emb2[:5].tolist()\n",
    "#     }\n",
    "#     return similarity, details\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 2.  DataFrame-level helper\n",
    "# # ------------------------------------------------------------------\n",
    "# def add_transformer_similarity(df: pd.DataFrame,\n",
    "#                                pairs: Iterable[Tuple[str, str]] = (\n",
    "#                                    (\"y_train\", \"y_pred\"),\n",
    "#                                    (\"y_pred\",  \"y_test\"),\n",
    "#                                    (\"y_train\", \"y_test\")\n",
    "#                                ),\n",
    "#                                keep_details: bool = False,\n",
    "#                                model: SentenceTransformer = _SBERT_MODEL\n",
    "#                                ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Append semantic similarity columns computed with a Sentence-BERT model.\n",
    "\n",
    "#     • For each (colA, colB) you get '<colA>_vs_<colB>_sbert_sim'  (float, –1‥1).  \n",
    "#       (Because embeddings are normalised, scores are usually 0‥1 for\n",
    "#        “reasonably related” English texts; negatives mean strong dissimilarity.)\n",
    "\n",
    "#     • With *keep_details=True* a companion\n",
    "#       '<pair>_sbert_sim_details' column is added containing the two\n",
    "#       1 024-D vectors’ first five dimensions.\n",
    "\n",
    "#     • Pass your own *model* if you want a different checkpoint\n",
    "#       (e.g. multilingual or domain-specific).\n",
    "#     \"\"\"\n",
    "#     for a, b in pairs:\n",
    "#         sim_col = f\"{a}_vs_{b}_sbert_sim\"\n",
    "\n",
    "#         if keep_details:\n",
    "#             det_col = f\"{a}_vs_{b}_sbert_sim_details\"\n",
    "\n",
    "#             def _compare(row):\n",
    "#                 sim, det = transformer_similarity(row[a], row[b], model)\n",
    "#                 return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "#             df[[sim_col, det_col]] = df.apply(_compare, axis=1)\n",
    "\n",
    "#         else:\n",
    "#             df[sim_col] = df.apply(\n",
    "#                 lambda r: transformer_similarity(r[a], r[b], model)[0],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7ec6ef0-10c4-4b79-a6c2-b0a1b4989378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = add_transformer_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b3c46-78ef-4110-98a9-c9d4db610068",
   "metadata": {},
   "source": [
    "### POS Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a0ebf5b-6a7a-4feb-9c03-67c5d707d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/konstantinoskatharakes/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/konstantinoskatharakes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/konstantinoskatharakes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def get_pos_distribution(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get the distribution of POS tags in the text.\n",
    "    Returns a dictionary with POS tags as keys and their frequencies as values.\n",
    "    \"\"\"\n",
    "    # Tokenize and get POS tags\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Count POS tag frequencies\n",
    "    pos_dist = {}\n",
    "    for _, tag in pos_tags:\n",
    "        pos_dist[tag] = pos_dist.get(tag, 0) + 1\n",
    "    \n",
    "    # Normalize frequencies\n",
    "    total = sum(pos_dist.values())\n",
    "    for tag in pos_dist:\n",
    "        pos_dist[tag] = pos_dist[tag] / total\n",
    "        \n",
    "    return pos_dist\n",
    "\n",
    "def pos_similarity(text1: str, text2: str) -> Tuple[float, dict]:\n",
    "    \"\"\"\n",
    "    Compare two texts based on their POS tag distributions.\n",
    "    Returns a similarity score and the POS distributions.\n",
    "    \"\"\"\n",
    "    # Get POS distributions\n",
    "    dist1 = get_pos_distribution(text1)\n",
    "    dist2 = get_pos_distribution(text2)\n",
    "    \n",
    "    # Get all unique POS tags\n",
    "    all_tags = set(dist1.keys()) | set(dist2.keys())\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    vec1 = np.array([dist1.get(tag, 0) for tag in all_tags])\n",
    "    vec2 = np.array([dist2.get(tag, 0) for tag in all_tags])\n",
    "    \n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    \n",
    "    return similarity, {\"text1_pos\": dist1, \"text2_pos\": dist2}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0.  once-per-session NLTK housekeeping\n",
    "# ------------------------------------------------------------------\n",
    "import nltk, numpy as np, pandas as pd\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from typing import Dict, Tuple, Iterable\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  low-level POS helpers\n",
    "# ------------------------------------------------------------------\n",
    "def get_pos_distribution(text: str | None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Return a normalised frequency table of Penn-Treebank POS tags.\n",
    "    \"\"\"\n",
    "    tokens  = word_tokenize(str(text or \"\").lower())\n",
    "    tags    = pos_tag(tokens)\n",
    "\n",
    "    counts  = {}\n",
    "    for _, tag in tags:\n",
    "        counts[tag] = counts.get(tag, 0) + 1\n",
    "\n",
    "    total   = sum(counts.values()) or 1\n",
    "    return {tag: c / total for tag, c in counts.items()}\n",
    "\n",
    "\n",
    "def pos_similarity(text1: str | None,\n",
    "                   text2: str | None\n",
    "                   ) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Cosine similarity between the two POS-tag distributions.\n",
    "    \"\"\"\n",
    "    dist1, dist2 = get_pos_distribution(text1), get_pos_distribution(text2)\n",
    "    all_tags     = set(dist1) | set(dist2)\n",
    "\n",
    "    v1 = np.array([dist1.get(tag, 0.0) for tag in all_tags])\n",
    "    v2 = np.array([dist2.get(tag, 0.0) for tag in all_tags])\n",
    "\n",
    "    sim = (np.dot(v1, v2) /\n",
    "           (np.linalg.norm(v1) * np.linalg.norm(v2))) if v1.any() and v2.any() else 0.0\n",
    "\n",
    "    return sim, {\"text1_pos\": dist1, \"text2_pos\": dist2}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  DataFrame-level helper  ➜  use exactly like the others\n",
    "# ------------------------------------------------------------------\n",
    "def add_pos_similarity(df: pd.DataFrame,\n",
    "                       pairs: Iterable[Tuple[str, str]] = (\n",
    "                           (\"y_train\", \"y_pred\"),\n",
    "                           (\"y_pred\",  \"y_test\"),\n",
    "                           (\"y_train\", \"y_test\")\n",
    "                       ),\n",
    "                       keep_details: bool = False\n",
    "                       ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append POS-distribution similarity columns.\n",
    "\n",
    "    • For each (colA, colB) → `<colA>_vs_<colB>_pos_sim` (float 0–1).  \n",
    "    • If *keep_details* is True, also add\n",
    "      `<pair>_pos_sim_details` with both normalised distributions.\n",
    "    \"\"\"\n",
    "    for a, b in pairs:\n",
    "        sim_col = f\"{a}_vs_{b}_pos_sim\"\n",
    "\n",
    "        if keep_details:\n",
    "            det_col = f\"{a}_vs_{b}_pos_sim_details\"\n",
    "\n",
    "            def _row(row):\n",
    "                sim, det = pos_similarity(row[a], row[b])\n",
    "                return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "            df[[sim_col, det_col]] = df.apply(_row, axis=1)\n",
    "        else:\n",
    "            df[sim_col] = df.apply(\n",
    "                lambda r: pos_similarity(r[a], r[b])[0],\n",
    "                axis=1\n",
    "            )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0922301a-1523-4d82-a29d-b9ac1217424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_pos_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f9558-668b-4273-b88a-576fcee05786",
   "metadata": {},
   "source": [
    "### Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66235558-ea4c-4393-9261-af89bdde1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_stats(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate average sentence length and other sentence statistics.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing sentence statistics\n",
    "    \"\"\"\n",
    "    # Clean and prepare text\n",
    "    text = text.strip()\n",
    "\n",
    "    # Split into sentences\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # Count words in each sentence\n",
    "    sentence_word_counts = [len(re.findall(r'\\b\\w+\\b', s)) for s in sentences]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_sentence_length = sum(sentence_word_counts) / len(sentences) if sentences else 0\n",
    "    median_length = np.median(sentence_word_counts) if sentences else 0\n",
    "    std_dev = np.std(sentence_word_counts) if sentences else 0\n",
    "    \n",
    "    return {\n",
    "        \"avg_sentence_length\": avg_sentence_length,\n",
    "        \"median_sentence_length\": median_length,\n",
    "        \"std_deviation\": std_dev,\n",
    "        \"total_sentences\": len(sentences),\n",
    "        \"sentence_lengths\": sentence_word_counts\n",
    "    }\n",
    "\n",
    "def sentence_length_similarity(text1: str, text2: str) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Compare two texts based on their average sentence lengths.\n",
    "    Returns a similarity score and the sentence statistics.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): First text to compare\n",
    "        text2 (str): Second text to compare\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - similarity score (float): 1.0 means identical average sentence length, \n",
    "          closer to 0.0 means more different\n",
    "        - dictionary with sentence statistics for both texts\n",
    "    \"\"\"\n",
    "    # Get sentence statistics\n",
    "    stats1 = calculate_sentence_stats(text1)\n",
    "    stats2 = calculate_sentence_stats(text2)\n",
    "    \n",
    "    # Calculate similarity as the ratio of the shorter average to the longer one\n",
    "    # This gives a value between 0 and 1, where 1 means identical average lengths\n",
    "    avg1 = stats1[\"avg_sentence_length\"]\n",
    "    avg2 = stats2[\"avg_sentence_length\"]\n",
    "    \n",
    "    if avg1 == 0 and avg2 == 0:  # Edge case: both texts have no sentences\n",
    "        similarity = 1.0\n",
    "    elif avg1 == 0 or avg2 == 0:  # Edge case: one text has no sentences\n",
    "        similarity = 0.0\n",
    "    else:\n",
    "        similarity = min(avg1, avg2) / max(avg1, avg2)\n",
    "    \n",
    "    return similarity, {\n",
    "        \"text1_stats\": stats1,\n",
    "        \"text2_stats\": stats2,\n",
    "        \"difference\": avg2 - avg1  # positive if text2 has longer sentences\n",
    "    }\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  imports once per file\n",
    "# ----------------------------------------------------------------------\n",
    "import re, numpy as np, pandas as pd\n",
    "from typing import Dict, Tuple, Iterable\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  low-level sentence-length helpers  (your originals, unchanged)\n",
    "# ----------------------------------------------------------------------\n",
    "def calculate_sentence_stats(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Return average-, median-, std-sentence length plus raw lengths list.\n",
    "    \"\"\"\n",
    "    text = str(text or \"\").strip()\n",
    "\n",
    "    # crude sentence split (period / exclam / question)\n",
    "    sentences = re.split(r\"[.!?]+\", text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    lengths = [len(re.findall(r\"\\b\\w+\\b\", s)) for s in sentences]\n",
    "\n",
    "    avg = sum(lengths) / len(sentences) if sentences else 0.0\n",
    "\n",
    "    return {\n",
    "        \"avg_sentence_length\": avg,\n",
    "        \"median_sentence_length\": float(np.median(lengths)) if lengths else 0.0,\n",
    "        \"std_deviation\": float(np.std(lengths)) if lengths else 0.0,\n",
    "        \"total_sentences\": len(sentences),\n",
    "        \"sentence_lengths\": lengths,\n",
    "    }\n",
    "\n",
    "\n",
    "def sentence_length_similarity(text1: str,\n",
    "                               text2: str\n",
    "                               ) -> Tuple[float, Dict]:\n",
    "    \"\"\"Similarity = min(avg1, avg2) / max(avg1, avg2) (range 0–1).\"\"\"\n",
    "    stats1, stats2 = (calculate_sentence_stats(text1),\n",
    "                      calculate_sentence_stats(text2))\n",
    "\n",
    "    avg1, avg2 = stats1[\"avg_sentence_length\"], stats2[\"avg_sentence_length\"]\n",
    "\n",
    "    if avg1 == avg2 == 0:\n",
    "        sim = 1.0\n",
    "    elif avg1 == 0 or avg2 == 0:\n",
    "        sim = 0.0\n",
    "    else:\n",
    "        sim = min(avg1, avg2) / max(avg1, avg2)\n",
    "\n",
    "    details = {\n",
    "        \"text1_stats\": stats1,\n",
    "        \"text2_stats\": stats2,\n",
    "        \"difference\": avg2 - avg1,\n",
    "    }\n",
    "    return sim, details\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  DataFrame-level helper  ➜  call just like add_stopword_similarity()\n",
    "# ----------------------------------------------------------------------\n",
    "def add_sentence_length_similarity(df: pd.DataFrame,\n",
    "                                   pairs: Iterable[Tuple[str, str]] = (\n",
    "                                       (\"y_train\", \"y_pred\"),\n",
    "                                       (\"y_pred\",  \"y_test\"),\n",
    "                                       (\"y_train\", \"y_test\"),\n",
    "                                   ),\n",
    "                                   keep_details: bool = False\n",
    "                                   ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append per-row sentence-length similarity columns.\n",
    "\n",
    "    • Each (colA, colB) pair adds\n",
    "        '<colA>_vs_<colB>_sentlen_sim'            (float 0–1)\n",
    "\n",
    "    • If *keep_details* is True a companion\n",
    "        '<pair>_sentlen_sim_details'\n",
    "      column contains the full stats dict.\n",
    "    \"\"\"\n",
    "    for a, b in pairs:\n",
    "        sim_col = f\"{a}_vs_{b}_sentlen_sim\"\n",
    "\n",
    "        if keep_details:\n",
    "            det_col = f\"{a}_vs_{b}_sentlen_sim_details\"\n",
    "\n",
    "            def _row(row):\n",
    "                sim, det = sentence_length_similarity(row[a], row[b])\n",
    "                return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "            df[[sim_col, det_col]] = df.apply(_row, axis=1)\n",
    "\n",
    "        else:\n",
    "            df[sim_col] = df.apply(\n",
    "                lambda r: sentence_length_similarity(r[a], r[b])[0],\n",
    "                axis=1\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e33d745-3736-442f-bda5-f89b28277310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_sentence_length_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db38e99-d0c4-479f-a2fb-ffededda9839",
   "metadata": {},
   "source": [
    "### Text Frequency - Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63dc3a04-4049-4418-be46-64b0cf5aa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict, List, Any, Union\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess text by lowercasing and normalizing whitespace.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to preprocess\n",
    "        \n",
    "    Returns:\n",
    "        str: Preprocessed text\n",
    "    \"\"\"\n",
    "    # Simple preprocessing - sklearn's TfidfVectorizer will handle tokenization\n",
    "    return text.lower()\n",
    "\n",
    "def extract_top_features(tfidf_matrix: np.ndarray, feature_names: np.ndarray, top_n: int = 10) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Extract top weighted features from TF-IDF matrix for a document.\n",
    "    \n",
    "    Args:\n",
    "        tfidf_matrix (np.ndarray): Row of the TF-IDF matrix for a document\n",
    "        feature_names (np.ndarray): Array of feature names\n",
    "        top_n (int): Number of top features to extract\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary of top features with their weights\n",
    "    \"\"\"\n",
    "    # Get indices of top weighted features\n",
    "    top_indices = np.argsort(tfidf_matrix)[::-1][:top_n]\n",
    "    \n",
    "    # Create a dictionary of feature names and their weights\n",
    "    top_features = {feature_names[i]: float(tfidf_matrix[i]) for i in top_indices if tfidf_matrix[i] > 0}\n",
    "    \n",
    "    return top_features\n",
    "\n",
    "def analyze_unique_features(weights1: np.ndarray, weights2: np.ndarray, feature_names: np.ndarray, top_n: int = 5) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Find features that are unique to each text.\n",
    "    \n",
    "    Args:\n",
    "        weights1 (np.ndarray): TF-IDF weights for first text\n",
    "        weights2 (np.ndarray): TF-IDF weights for second text\n",
    "        feature_names (np.ndarray): Array of feature names\n",
    "        top_n (int): Number of top unique features to extract\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List[str]]: Dictionary with unique features for each text\n",
    "    \"\"\"\n",
    "    # Features present in text1 but not in text2\n",
    "    unique_to_text1 = [(i, weights1[i]) for i in range(len(weights1)) if weights1[i] > 0 and weights2[i] == 0]\n",
    "    unique_to_text1.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Features present in text2 but not in text1\n",
    "    unique_to_text2 = [(i, weights2[i]) for i in range(len(weights2)) if weights2[i] > 0 and weights1[i] == 0]\n",
    "    unique_to_text2.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract feature names\n",
    "    unique_features_text1 = [feature_names[idx] for idx, _ in unique_to_text1[:top_n]]\n",
    "    unique_features_text2 = [feature_names[idx] for idx, _ in unique_to_text2[:top_n]]\n",
    "    \n",
    "    return {\n",
    "        \"unique_to_text1\": unique_features_text1,\n",
    "        \"unique_to_text2\": unique_features_text2\n",
    "    }\n",
    "\n",
    "def tfidf_similarity(text1: str, text2: str, ngram_range: Tuple[int, int] = (1, 3), remove_stopwords: bool = True) -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Compare two texts using TF-IDF vectors across multiple n-gram ranges.\n",
    "    \n",
    "    Args:\n",
    "        text1 (str): First text to compare\n",
    "        text2 (str): Second text to compare\n",
    "        ngram_range (tuple): Range of n-gram sizes to include (min, max)\n",
    "        remove_stopwords (bool): Whether to remove stopwords\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[float, Dict]: A tuple containing:\n",
    "            - A similarity score between 0-1\n",
    "            - A dictionary with detailed metrics\n",
    "    \"\"\"\n",
    "    # Preprocess texts\n",
    "    processed_text1 = preprocess_text(text1)\n",
    "    processed_text2 = preprocess_text(text2)\n",
    "    \n",
    "    # Process stopwords if needed\n",
    "    stop_words = 'english' if remove_stopwords else None\n",
    "    \n",
    "    # Create vectorizer for the specified n-gram range\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=ngram_range, \n",
    "        stop_words=stop_words,\n",
    "        sublinear_tf=True  # Apply sublinear scaling to term frequencies\n",
    "    )\n",
    "    \n",
    "    # Fit and transform both texts\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([processed_text1, processed_text2])\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "    except ValueError as e:\n",
    "        # Handle empty corpus or other vectorization errors\n",
    "        return 0.0, {\"error\": str(e)}\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    if tfidf_matrix.shape[1] > 0:  # Ensure we have features\n",
    "        # Convert sparse matrix to dense for simpler operations\n",
    "        dense_matrix = tfidf_matrix.toarray()\n",
    "        # Calculate cosine similarity\n",
    "        dot_product = np.dot(dense_matrix[0], dense_matrix[1])\n",
    "        norm_text1 = np.linalg.norm(dense_matrix[0])\n",
    "        norm_text2 = np.linalg.norm(dense_matrix[1])\n",
    "        \n",
    "        if norm_text1 > 0 and norm_text2 > 0:  # Avoid division by zero\n",
    "            similarity = dot_product / (norm_text1 * norm_text2)\n",
    "        else:\n",
    "            similarity = 0.0\n",
    "    else:\n",
    "        similarity = 0.0\n",
    "    \n",
    "    # Extract top features for each text\n",
    "    if tfidf_matrix.shape[1] > 0:\n",
    "        dense_matrix = tfidf_matrix.toarray()\n",
    "        top_features1 = extract_top_features(dense_matrix[0], feature_names)\n",
    "        top_features2 = extract_top_features(dense_matrix[1], feature_names)\n",
    "        \n",
    "        # Analyze unique features\n",
    "        unique_features = analyze_unique_features(dense_matrix[0], dense_matrix[1], feature_names)\n",
    "        \n",
    "        # Get n-gram level statistics\n",
    "        ngram_stats = {}\n",
    "        for n in range(ngram_range[0], ngram_range[1] + 1):\n",
    "            # Filter features by n-gram length\n",
    "            n_gram_features = [f for f in feature_names if len(f.split()) == n]\n",
    "            if n_gram_features:\n",
    "                ngram_stats[f\"{n}-gram\"] = len(n_gram_features)\n",
    "    else:\n",
    "        top_features1 = {}\n",
    "        top_features2 = {}\n",
    "        unique_features = {\"unique_to_text1\": [], \"unique_to_text2\": []}\n",
    "        ngram_stats = {}\n",
    "    \n",
    "    # Prepare detailed output\n",
    "    details = {\n",
    "        \"similarity\": similarity,\n",
    "        \"ngram_range\": ngram_range,\n",
    "        \"stopwords_removed\": remove_stopwords,\n",
    "        \"top_features_text1\": top_features1,\n",
    "        \"top_features_text2\": top_features2,\n",
    "        \"unique_features\": unique_features,\n",
    "        \"ngram_stats\": ngram_stats,\n",
    "        \"vectorizer_vocabulary_size\": len(feature_names) if feature_names is not None else 0\n",
    "    }\n",
    "    \n",
    "    return similarity, details\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  once-per-file imports\n",
    "# ----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "# keep the tf-idf functions you already wrote in the same module:\n",
    "# • preprocess_text\n",
    "# • tfidf_similarity\n",
    "# (they need nltk + scikit-learn, already imported in your snippet)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  DataFrame-level helper\n",
    "# ----------------------------------------------------------------------\n",
    "def add_tfidf_similarity(\n",
    "    df: pd.DataFrame,\n",
    "    pairs: Iterable[Tuple[str, str]] = (\n",
    "        (\"y_train\", \"y_pred\"),\n",
    "        (\"y_pred\",  \"y_test\"),\n",
    "        (\"y_train\", \"y_test\"),\n",
    "    ),\n",
    "    ngram_range: Tuple[int, int] = (1, 1),\n",
    "    remove_stopwords: bool = False,\n",
    "    keep_details: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append per-row TF-IDF cosine-similarity columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Frame that already contains the text columns.\n",
    "    pairs : iterable[(str, str)]\n",
    "        Column pairs to compare.\n",
    "    ngram_range : (min_n, max_n)\n",
    "        Passed to `tfidf_similarity` (default = unigrams–trigrams).\n",
    "    remove_stopwords : bool\n",
    "        Whether the vectoriser should ignore English stop-words.\n",
    "    keep_details : bool\n",
    "        • False → only a '<pair>_tfidf_sim' column (float 0–1).  \n",
    "        • True  → an additional '<pair>_tfidf_sim_details' column\n",
    "          with the full diagnostics dict from `tfidf_similarity`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Same frame, with added similarity (and optional details) columns.\n",
    "    \"\"\"\n",
    "    for a, b in pairs:\n",
    "        sim_col = f\"{a}_vs_{b}_tfidf_sim\"\n",
    "\n",
    "        if keep_details:\n",
    "            det_col = f\"{a}_vs_{b}_tfidf_sim_details\"\n",
    "\n",
    "            def _row(row):\n",
    "                sim, det = tfidf_similarity(\n",
    "                    row[a],\n",
    "                    row[b],\n",
    "                    ngram_range=ngram_range,\n",
    "                    remove_stopwords=remove_stopwords,\n",
    "                )\n",
    "                return pd.Series({sim_col: sim, det_col: det})\n",
    "\n",
    "            df[[sim_col, det_col]] = df.apply(_row, axis=1)\n",
    "\n",
    "        else:\n",
    "            df[sim_col] = df.apply(\n",
    "                lambda r: tfidf_similarity(\n",
    "                    r[a],\n",
    "                    r[b],\n",
    "                    ngram_range=ngram_range,\n",
    "                    remove_stopwords=remove_stopwords,\n",
    "                )[0],\n",
    "                axis=1,\n",
    "            )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d9881b5-d431-4b7c-9ec9-fca60465fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_tfidf_similarity(df, keep_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9400d090-0032-4c3d-9bbe-c1c71507a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Final_dataset.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d32d683-063b-46f5-86ab-faeb9d75e0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "      <th>common_unigrams_y_pred_test</th>\n",
       "      <th>common_bigrams_y_pred_test</th>\n",
       "      <th>common_trigrams_y_pred_test</th>\n",
       "      <th>common_unigrams_y_pred_train</th>\n",
       "      <th>common_bigrams_y_pred_train</th>\n",
       "      <th>...</th>\n",
       "      <th>y_train_vs_y_test_ttr_sim</th>\n",
       "      <th>y_train_vs_y_pred_pos_sim</th>\n",
       "      <th>y_pred_vs_y_test_pos_sim</th>\n",
       "      <th>y_train_vs_y_test_pos_sim</th>\n",
       "      <th>y_train_vs_y_pred_sentlen_sim</th>\n",
       "      <th>y_pred_vs_y_test_sentlen_sim</th>\n",
       "      <th>y_train_vs_y_test_sentlen_sim</th>\n",
       "      <th>y_train_vs_y_pred_tfidf_sim</th>\n",
       "      <th>y_pred_vs_y_test_tfidf_sim</th>\n",
       "      <th>y_train_vs_y_test_tfidf_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark_Twain</td>\n",
       "      <td>THE MAN THAT CORRUPTED HADLEYBURG.txt</td>\n",
       "      <td>THE MAN THAT CORRUPTED HADLEYBURG\\n\\nAND OTHER...</td>\n",
       "      <td>He made a\\ntrip to Hadleyburg and found it the...</td>\n",
       "      <td>joy. He began to form a plan at once, saying t...</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934055</td>\n",
       "      <td>0.962196</td>\n",
       "      <td>0.945538</td>\n",
       "      <td>0.948423</td>\n",
       "      <td>0.538851</td>\n",
       "      <td>0.826777</td>\n",
       "      <td>0.445510</td>\n",
       "      <td>0.370351</td>\n",
       "      <td>0.274771</td>\n",
       "      <td>0.287364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark_Twain</td>\n",
       "      <td>To the Person Sitting in Darkness.txt</td>\n",
       "      <td>TO THE PERSON SITTING IN DARKNESS\\n\\n\\n       ...</td>\n",
       "      <td>And\\nthere is more of it. The People who Sit i...</td>\n",
       "      <td>Game. It shows that these new players of it ar...</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927173</td>\n",
       "      <td>0.877965</td>\n",
       "      <td>0.864209</td>\n",
       "      <td>0.964112</td>\n",
       "      <td>0.879538</td>\n",
       "      <td>0.640734</td>\n",
       "      <td>0.728489</td>\n",
       "      <td>0.369874</td>\n",
       "      <td>0.243572</td>\n",
       "      <td>0.346954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark_Twain</td>\n",
       "      <td>Life on the Mississippi.txt</td>\n",
       "      <td>Produced by David Widger. Earliest PG text edi...</td>\n",
       "      <td>A New Plan.--A Little Tact.--The Mayor is\\nHir...</td>\n",
       "      <td>rd. CHAPTER XXIII. Old French Settlements.--We...</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887572</td>\n",
       "      <td>0.910531</td>\n",
       "      <td>0.894371</td>\n",
       "      <td>0.995097</td>\n",
       "      <td>0.977095</td>\n",
       "      <td>0.941602</td>\n",
       "      <td>0.963675</td>\n",
       "      <td>0.164692</td>\n",
       "      <td>0.180605</td>\n",
       "      <td>0.227837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark_Twain</td>\n",
       "      <td>A Horse's Tale.txt</td>\n",
       "      <td>A Horse’s Tale\\n\\n\\n                          ...</td>\n",
       "      <td>* * * * *\\n\\n\\nA Horse’s Tale\\n\\nCHAP. I.\\nSOL...</td>\n",
       "      <td>rian will correct these defects.” The cats in ...</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918855</td>\n",
       "      <td>0.903443</td>\n",
       "      <td>0.875433</td>\n",
       "      <td>0.928989</td>\n",
       "      <td>0.556345</td>\n",
       "      <td>0.917051</td>\n",
       "      <td>0.510197</td>\n",
       "      <td>0.265685</td>\n",
       "      <td>0.253564</td>\n",
       "      <td>0.330454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mark_Twain</td>\n",
       "      <td>1601 Conversation as it was by the Social Fire...</td>\n",
       "      <td>1601\\n\\nConversation as it was by the Social F...</td>\n",
       "      <td>The first edition of it was published\\nin 1880...</td>\n",
       "      <td>601. The piece is a supposititious conversatio...</td>\n",
       "      <td>53</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995280</td>\n",
       "      <td>0.938622</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>0.989911</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.751918</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.366840</td>\n",
       "      <td>0.322166</td>\n",
       "      <td>0.333211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Robin Hanson</td>\n",
       "      <td>Prestige in US Today.txt</td>\n",
       "      <td>Lauren A. Rivera’s Pedigree: How Elite Student...</td>\n",
       "      <td>So, this is a system that is self-reinforcing,...</td>\n",
       "      <td>It seems that while these firms do sell concre...</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939551</td>\n",
       "      <td>0.876522</td>\n",
       "      <td>0.864894</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.657471</td>\n",
       "      <td>0.916475</td>\n",
       "      <td>0.309852</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>0.363796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Robin Hanson</td>\n",
       "      <td>AI Risk, Again.txt</td>\n",
       "      <td>Large language models like ChatGPT have recent...</td>\n",
       "      <td>(The future world could be a world of many AIs...</td>\n",
       "      <td>Of course the owners of such future ventures, ...</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945580</td>\n",
       "      <td>0.919564</td>\n",
       "      <td>0.932777</td>\n",
       "      <td>0.982412</td>\n",
       "      <td>0.861481</td>\n",
       "      <td>0.688020</td>\n",
       "      <td>0.798648</td>\n",
       "      <td>0.332692</td>\n",
       "      <td>0.275696</td>\n",
       "      <td>0.366223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Robin Hanson</td>\n",
       "      <td>New Tax Career Agent Test.txt</td>\n",
       "      <td>If that taxpayer approved, the taxes that he o...</td>\n",
       "      <td>If the worker who gets the TCA has a higher ex...</td>\n",
       "      <td>Bids should give direct estimates of worker va...</td>\n",
       "      <td>61</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962536</td>\n",
       "      <td>0.962763</td>\n",
       "      <td>0.943678</td>\n",
       "      <td>0.968653</td>\n",
       "      <td>0.942137</td>\n",
       "      <td>0.972364</td>\n",
       "      <td>0.916100</td>\n",
       "      <td>0.379268</td>\n",
       "      <td>0.392012</td>\n",
       "      <td>0.411402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Robin Hanson</td>\n",
       "      <td>A Perfect Storm of Inflexibility.txt</td>\n",
       "      <td>Most biological species specialize for particu...</td>\n",
       "      <td>But the problem is that, in peace time, this m...</td>\n",
       "      <td>In addition to these two considerations, longe...</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943198</td>\n",
       "      <td>0.959473</td>\n",
       "      <td>0.952826</td>\n",
       "      <td>0.970158</td>\n",
       "      <td>0.878442</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.765576</td>\n",
       "      <td>0.458430</td>\n",
       "      <td>0.255961</td>\n",
       "      <td>0.307586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Robin Hanson</td>\n",
       "      <td>Culture Policy Is Neglected.txt</td>\n",
       "      <td>Long ago in physics I learned of the Union of ...</td>\n",
       "      <td>But in the current case, the demographic trans...</td>\n",
       "      <td>So if we could go back to Tenochtitlan or Rome...</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914901</td>\n",
       "      <td>0.912322</td>\n",
       "      <td>0.941133</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.923837</td>\n",
       "      <td>0.839895</td>\n",
       "      <td>0.363474</td>\n",
       "      <td>0.359832</td>\n",
       "      <td>0.347434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author                                              Title  \\\n",
       "0      Mark_Twain              THE MAN THAT CORRUPTED HADLEYBURG.txt   \n",
       "1      Mark_Twain              To the Person Sitting in Darkness.txt   \n",
       "2      Mark_Twain                        Life on the Mississippi.txt   \n",
       "3      Mark_Twain                                 A Horse's Tale.txt   \n",
       "4      Mark_Twain  1601 Conversation as it was by the Social Fire...   \n",
       "..            ...                                                ...   \n",
       "393  Robin Hanson                           Prestige in US Today.txt   \n",
       "394  Robin Hanson                                 AI Risk, Again.txt   \n",
       "395  Robin Hanson                      New Tax Career Agent Test.txt   \n",
       "396  Robin Hanson               A Perfect Storm of Inflexibility.txt   \n",
       "397  Robin Hanson                    Culture Policy Is Neglected.txt   \n",
       "\n",
       "                                               y_train  \\\n",
       "0    THE MAN THAT CORRUPTED HADLEYBURG\\n\\nAND OTHER...   \n",
       "1    TO THE PERSON SITTING IN DARKNESS\\n\\n\\n       ...   \n",
       "2    Produced by David Widger. Earliest PG text edi...   \n",
       "3    A Horse’s Tale\\n\\n\\n                          ...   \n",
       "4    1601\\n\\nConversation as it was by the Social F...   \n",
       "..                                                 ...   \n",
       "393  Lauren A. Rivera’s Pedigree: How Elite Student...   \n",
       "394  Large language models like ChatGPT have recent...   \n",
       "395  If that taxpayer approved, the taxes that he o...   \n",
       "396  Most biological species specialize for particu...   \n",
       "397  Long ago in physics I learned of the Union of ...   \n",
       "\n",
       "                                                y_pred  \\\n",
       "0    He made a\\ntrip to Hadleyburg and found it the...   \n",
       "1    And\\nthere is more of it. The People who Sit i...   \n",
       "2    A New Plan.--A Little Tact.--The Mayor is\\nHir...   \n",
       "3    * * * * *\\n\\n\\nA Horse’s Tale\\n\\nCHAP. I.\\nSOL...   \n",
       "4    The first edition of it was published\\nin 1880...   \n",
       "..                                                 ...   \n",
       "393  So, this is a system that is self-reinforcing,...   \n",
       "394  (The future world could be a world of many AIs...   \n",
       "395  If the worker who gets the TCA has a higher ex...   \n",
       "396  But the problem is that, in peace time, this m...   \n",
       "397  But in the current case, the demographic trans...   \n",
       "\n",
       "                                                y_test  \\\n",
       "0    joy. He began to form a plan at once, saying t...   \n",
       "1    Game. It shows that these new players of it ar...   \n",
       "2    rd. CHAPTER XXIII. Old French Settlements.--We...   \n",
       "3    rian will correct these defects.” The cats in ...   \n",
       "4    601. The piece is a supposititious conversatio...   \n",
       "..                                                 ...   \n",
       "393  It seems that while these firms do sell concre...   \n",
       "394  Of course the owners of such future ventures, ...   \n",
       "395  Bids should give direct estimates of worker va...   \n",
       "396  In addition to these two considerations, longe...   \n",
       "397  So if we could go back to Tenochtitlan or Rome...   \n",
       "\n",
       "     common_unigrams_y_pred_test  common_bigrams_y_pred_test  \\\n",
       "0                             43                          20   \n",
       "1                             28                          16   \n",
       "2                             33                          49   \n",
       "3                             38                          21   \n",
       "4                             53                          34   \n",
       "..                           ...                         ...   \n",
       "393                           49                          19   \n",
       "394                           44                          20   \n",
       "395                           61                          40   \n",
       "396                           47                          18   \n",
       "397                           64                          41   \n",
       "\n",
       "     common_trigrams_y_pred_test  common_unigrams_y_pred_train  \\\n",
       "0                              4                            50   \n",
       "1                              3                            31   \n",
       "2                             43                            17   \n",
       "3                              7                            41   \n",
       "4                              6                            58   \n",
       "..                           ...                           ...   \n",
       "393                            2                            51   \n",
       "394                            3                            49   \n",
       "395                            6                            67   \n",
       "396                            2                            83   \n",
       "397                            9                            75   \n",
       "\n",
       "     common_bigrams_y_pred_train  ...  y_train_vs_y_test_ttr_sim  \\\n",
       "0                             28  ...                   0.934055   \n",
       "1                             33  ...                   0.927173   \n",
       "2                             13  ...                   0.887572   \n",
       "3                             28  ...                   0.918855   \n",
       "4                             42  ...                   0.995280   \n",
       "..                           ...  ...                        ...   \n",
       "393                           35  ...                   0.939551   \n",
       "394                           38  ...                   0.945580   \n",
       "395                           44  ...                   0.962536   \n",
       "396                           61  ...                   0.943198   \n",
       "397                           45  ...                   0.914901   \n",
       "\n",
       "     y_train_vs_y_pred_pos_sim  y_pred_vs_y_test_pos_sim  \\\n",
       "0                     0.962196                  0.945538   \n",
       "1                     0.877965                  0.864209   \n",
       "2                     0.910531                  0.894371   \n",
       "3                     0.903443                  0.875433   \n",
       "4                     0.938622                  0.943471   \n",
       "..                         ...                       ...   \n",
       "393                   0.876522                  0.864894   \n",
       "394                   0.919564                  0.932777   \n",
       "395                   0.962763                  0.943678   \n",
       "396                   0.959473                  0.952826   \n",
       "397                   0.912322                  0.941133   \n",
       "\n",
       "     y_train_vs_y_test_pos_sim y_train_vs_y_pred_sentlen_sim  \\\n",
       "0                     0.948423                      0.538851   \n",
       "1                     0.964112                      0.879538   \n",
       "2                     0.995097                      0.977095   \n",
       "3                     0.928989                      0.556345   \n",
       "4                     0.989911                      0.895141   \n",
       "..                         ...                           ...   \n",
       "393                   0.974111                      0.717391   \n",
       "394                   0.982412                      0.861481   \n",
       "395                   0.968653                      0.942137   \n",
       "396                   0.970158                      0.878442   \n",
       "397                   0.947497                      0.909138   \n",
       "\n",
       "    y_pred_vs_y_test_sentlen_sim y_train_vs_y_test_sentlen_sim  \\\n",
       "0                       0.826777                      0.445510   \n",
       "1                       0.640734                      0.728489   \n",
       "2                       0.941602                      0.963675   \n",
       "3                       0.917051                      0.510197   \n",
       "4                       0.751918                      0.840000   \n",
       "..                           ...                           ...   \n",
       "393                     0.657471                      0.916475   \n",
       "394                     0.688020                      0.798648   \n",
       "395                     0.972364                      0.916100   \n",
       "396                     0.672515                      0.765576   \n",
       "397                     0.923837                      0.839895   \n",
       "\n",
       "     y_train_vs_y_pred_tfidf_sim  y_pred_vs_y_test_tfidf_sim  \\\n",
       "0                       0.370351                    0.274771   \n",
       "1                       0.369874                    0.243572   \n",
       "2                       0.164692                    0.180605   \n",
       "3                       0.265685                    0.253564   \n",
       "4                       0.366840                    0.322166   \n",
       "..                           ...                         ...   \n",
       "393                     0.309852                    0.279250   \n",
       "394                     0.332692                    0.275696   \n",
       "395                     0.379268                    0.392012   \n",
       "396                     0.458430                    0.255961   \n",
       "397                     0.363474                    0.359832   \n",
       "\n",
       "     y_train_vs_y_test_tfidf_sim  \n",
       "0                       0.287364  \n",
       "1                       0.346954  \n",
       "2                       0.227837  \n",
       "3                       0.330454  \n",
       "4                       0.333211  \n",
       "..                           ...  \n",
       "393                     0.363796  \n",
       "394                     0.366223  \n",
       "395                     0.411402  \n",
       "396                     0.307586  \n",
       "397                     0.347434  \n",
       "\n",
       "[398 rows x 38 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7666e-b07d-45d8-926c-02f6d538069b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
